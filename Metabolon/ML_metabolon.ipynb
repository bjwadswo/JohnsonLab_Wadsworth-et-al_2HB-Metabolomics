{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "Try deep learning netwrok for binary classification of the metabolon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oxoadipate</th>\n",
       "      <th>kynurenate</th>\n",
       "      <th>Nformylmethionine</th>\n",
       "      <th>AMP</th>\n",
       "      <th>adenosinediphosphoriboseADPribose</th>\n",
       "      <th>hydroxyphenyllactateHPLA</th>\n",
       "      <th>betaalanine</th>\n",
       "      <th>carnosine</th>\n",
       "      <th>phosphocholine</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>...</th>\n",
       "      <th>hydroxydecanoylcarnitine</th>\n",
       "      <th>succinoyltaurine</th>\n",
       "      <th>hexanoyltaurine</th>\n",
       "      <th>Nacetylaminoadipate</th>\n",
       "      <th>ditertbutylphenol</th>\n",
       "      <th>NNdimethylpropro</th>\n",
       "      <th>oxindolylalanine</th>\n",
       "      <th>oleylGPCO</th>\n",
       "      <th>avg_dVO2</th>\n",
       "      <th>avg_VO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.467669</td>\n",
       "      <td>-0.502356</td>\n",
       "      <td>0.604020</td>\n",
       "      <td>1.155266</td>\n",
       "      <td>0.554374</td>\n",
       "      <td>0.509589</td>\n",
       "      <td>-1.682942</td>\n",
       "      <td>-0.081640</td>\n",
       "      <td>-2.183583</td>\n",
       "      <td>0.550942</td>\n",
       "      <td>...</td>\n",
       "      <td>3.497966</td>\n",
       "      <td>-1.146348</td>\n",
       "      <td>-1.230095</td>\n",
       "      <td>-1.129802</td>\n",
       "      <td>-2.074813</td>\n",
       "      <td>-0.420198</td>\n",
       "      <td>-2.253050</td>\n",
       "      <td>0.949912</td>\n",
       "      <td>1.622066</td>\n",
       "      <td>-0.585547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.812456</td>\n",
       "      <td>-0.729896</td>\n",
       "      <td>1.735956</td>\n",
       "      <td>1.902503</td>\n",
       "      <td>-1.354648</td>\n",
       "      <td>0.655030</td>\n",
       "      <td>-0.986382</td>\n",
       "      <td>-0.271350</td>\n",
       "      <td>-0.577402</td>\n",
       "      <td>-0.863437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.775979</td>\n",
       "      <td>-0.561337</td>\n",
       "      <td>-1.104361</td>\n",
       "      <td>-0.734704</td>\n",
       "      <td>-0.781902</td>\n",
       "      <td>0.299352</td>\n",
       "      <td>-1.856883</td>\n",
       "      <td>-0.588613</td>\n",
       "      <td>1.450905</td>\n",
       "      <td>0.939831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341596</td>\n",
       "      <td>0.520124</td>\n",
       "      <td>-0.080949</td>\n",
       "      <td>1.064611</td>\n",
       "      <td>-1.072894</td>\n",
       "      <td>0.630093</td>\n",
       "      <td>2.124104</td>\n",
       "      <td>-0.199274</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.149239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428994</td>\n",
       "      <td>0.562333</td>\n",
       "      <td>0.303499</td>\n",
       "      <td>0.525386</td>\n",
       "      <td>-0.173917</td>\n",
       "      <td>-0.767051</td>\n",
       "      <td>-1.005226</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.556003</td>\n",
       "      <td>-0.499269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.696459</td>\n",
       "      <td>0.215898</td>\n",
       "      <td>-0.033017</td>\n",
       "      <td>-0.300402</td>\n",
       "      <td>-1.426641</td>\n",
       "      <td>-0.367192</td>\n",
       "      <td>0.047762</td>\n",
       "      <td>0.162822</td>\n",
       "      <td>0.566678</td>\n",
       "      <td>1.063032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.555703</td>\n",
       "      <td>-0.737090</td>\n",
       "      <td>-0.302112</td>\n",
       "      <td>0.749926</td>\n",
       "      <td>-0.775116</td>\n",
       "      <td>0.393152</td>\n",
       "      <td>-0.293635</td>\n",
       "      <td>-0.035675</td>\n",
       "      <td>0.496940</td>\n",
       "      <td>0.196349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.189109</td>\n",
       "      <td>-0.392664</td>\n",
       "      <td>-0.408489</td>\n",
       "      <td>1.392754</td>\n",
       "      <td>1.670193</td>\n",
       "      <td>-1.795812</td>\n",
       "      <td>-0.346030</td>\n",
       "      <td>0.315041</td>\n",
       "      <td>0.347505</td>\n",
       "      <td>-0.124541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077946</td>\n",
       "      <td>-1.270169</td>\n",
       "      <td>-1.126717</td>\n",
       "      <td>-0.509758</td>\n",
       "      <td>0.061403</td>\n",
       "      <td>-0.051534</td>\n",
       "      <td>-1.379212</td>\n",
       "      <td>-0.882308</td>\n",
       "      <td>0.761212</td>\n",
       "      <td>0.854730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   oxoadipate  kynurenate  Nformylmethionine       AMP   \n",
       "0   -1.467669   -0.502356           0.604020  1.155266  \\\n",
       "1    0.812456   -0.729896           1.735956  1.902503   \n",
       "2    0.341596    0.520124          -0.080949  1.064611   \n",
       "3    0.696459    0.215898          -0.033017 -0.300402   \n",
       "4    0.189109   -0.392664          -0.408489  1.392754   \n",
       "\n",
       "   adenosinediphosphoriboseADPribose  hydroxyphenyllactateHPLA  betaalanine   \n",
       "0                           0.554374                  0.509589    -1.682942  \\\n",
       "1                          -1.354648                  0.655030    -0.986382   \n",
       "2                          -1.072894                  0.630093     2.124104   \n",
       "3                          -1.426641                 -0.367192     0.047762   \n",
       "4                           1.670193                 -1.795812    -0.346030   \n",
       "\n",
       "   carnosine  phosphocholine  creatinine  ...  hydroxydecanoylcarnitine   \n",
       "0  -0.081640       -2.183583    0.550942  ...                  3.497966  \\\n",
       "1  -0.271350       -0.577402   -0.863437  ...                  1.775979   \n",
       "2  -0.199274        0.007674    0.149239  ...                  1.428994   \n",
       "3   0.162822        0.566678    1.063032  ...                  1.555703   \n",
       "4   0.315041        0.347505   -0.124541  ...                 -0.077946   \n",
       "\n",
       "   succinoyltaurine  hexanoyltaurine  Nacetylaminoadipate  ditertbutylphenol   \n",
       "0         -1.146348        -1.230095            -1.129802          -2.074813  \\\n",
       "1         -0.561337        -1.104361            -0.734704          -0.781902   \n",
       "2          0.562333         0.303499             0.525386          -0.173917   \n",
       "3         -0.737090        -0.302112             0.749926          -0.775116   \n",
       "4         -1.270169        -1.126717            -0.509758           0.061403   \n",
       "\n",
       "   NNdimethylpropro  oxindolylalanine  oleylGPCO  avg_dVO2   avg_VO2  \n",
       "0         -0.420198         -2.253050   0.949912  1.622066 -0.585547  \n",
       "1          0.299352         -1.856883  -0.588613  1.450905  0.939831  \n",
       "2         -0.767051         -1.005226   0.647059  0.556003 -0.499269  \n",
       "3          0.393152         -0.293635  -0.035675  0.496940  0.196349  \n",
       "4         -0.051534         -1.379212  -0.882308  0.761212  0.854730  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fwn = pd.read_csv('muscle_adjusted_values.csv') # reading data\n",
    "y = pd.DataFrame()\n",
    "# y['Ex'] = X_fwn.pop('Ex')\n",
    "y['Tx'] = X_fwn.pop('Tx')\n",
    "X_fwn = X_fwn.drop(['Group','MouseID','Ex'], axis=1)\n",
    "X_fwn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder() # creating instance of one-hot encoding function from sklearn\n",
    "y_fit = enc.fit_transform(y).toarray() # converting Ex and Tx columns to binary\n",
    "# y['Ex'] = y_fit[:,0] # assigning in correct order so that 1 = runner..\n",
    "# y['Tx'] = y_fit[:,2] # and 1 = 2HB\n",
    "y['Tx'] = y_fit[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tx\n",
       "0   1.0\n",
       "1   1.0\n",
       "2   1.0\n",
       "3   1.0\n",
       "4   1.0\n",
       "5   1.0\n",
       "6   1.0\n",
       "7   1.0\n",
       "8   1.0\n",
       "9   1.0\n",
       "10  1.0\n",
       "11  1.0\n",
       "12  0.0\n",
       "13  0.0\n",
       "14  0.0\n",
       "15  0.0\n",
       "16  0.0\n",
       "17  0.0\n",
       "18  0.0\n",
       "19  0.0\n",
       "20  0.0\n",
       "21  0.0\n",
       "22  0.0\n",
       "23  0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [X_fwn.shape[1]]\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64,activation = 'relu',input_shape = input_shape),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  3  4  5  6  7  9 10 13 15 19 20 21 22 23]\n",
      "  Test:  index=[ 2  8 11 12 14 16 17 18]\n",
      "Fold 1:\n",
      "  Train: index=[ 1  2  4  5  7  8 11 12 13 14 15 16 17 18 20 22]\n",
      "  Test:  index=[ 0  3  6  9 10 19 21 23]\n",
      "Fold 2:\n",
      "  Train: index=[ 0  2  3  6  8  9 10 11 12 14 16 17 18 19 21 23]\n",
      "  Test:  index=[ 1  4  5  7 13 15 20 22]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15a051120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_fwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "#simple performance reporting function - from Ken Jee\n",
    "def grid_performance(classifier, model_name):\n",
    "    print(model_name)\n",
    "    print('Best Score: ' + str(classifier.best_score_))\n",
    "    print('Best Parameters: ' + str(classifier.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost, Best Score: 0.9583333333333334,     Best Parameters: {'colsample_bytree': 0.1, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 2,     'min_child_weight': 0, 'n_estimators': 50, 'reg_alpha': 1.5, 'reg_lambda': 1,     'sampling_method': 'uniform', 'subsample': 0.9}'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "xgb = XGBClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [30, 50, 70],\n",
    "    'colsample_bytree': [0.05, 0.1, 0.15],\n",
    "    'max_depth': [2, 5, 8],\n",
    "    'reg_alpha': [1, 1.5],\n",
    "    'reg_lambda': [0.5, 1],\n",
    "    'subsample': [0.9, 1],\n",
    "    'learning_rate':[.05, 0.1, 0.15],\n",
    "    'gamma':[1,5,10],\n",
    "    'min_child_weight':[0],\n",
    "    'sampling_method': ['uniform']\n",
    "}\n",
    "grid_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 3, verbose = True, n_jobs = -1)\n",
    "# verbosity just controls how much feedback the program outputs for each candidate tested.\n",
    "# n_jobs = -1 means that we test all possible combinations based on hte range of inputs we gave\n",
    "best_xgb = grid_xgb.fit(X_fwn,y)\n",
    "grid_performance(best_xgb,'XGBoost')\n",
    "\"\"\"\n",
    "print(\"XGBoost, Best Score: 0.9583333333333334, \\\n",
    "    Best Parameters: {'colsample_bytree': 0.1, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 2, \\\n",
    "    'min_child_weight': 0, 'n_estimators': 50, 'reg_alpha': 1.5, 'reg_lambda': 1, \\\n",
    "    'sampling_method': 'uniform', 'subsample': 0.9}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013269183\n",
      "0 oxoadipate 0.057735324 529\n",
      "1 kynurenate 0.11092714 529\n",
      "2 Nformylmethionine 0.06048448 529\n",
      "3 AMP 0.6638415 529\n",
      "4 adenosinediphosphoriboseADPribose 0.34743387 529\n",
      "5 hydroxyphenyllactateHPLA 0.2610006 529\n",
      "6 betaalanine 0.3489922 529\n",
      "7 carnosine 0.47601575 529\n",
      "8 phosphocholine 0.21818027 529\n",
      "9 creatinine 0.34511146 529\n",
      "10 CMP 0.20312944 529\n",
      "11 dihydroxyacetonephosphateDHAP 0.053884167 529\n",
      "12 FAD 0.41341507 529\n",
      "13 gammaglutamylglutamate 0.21491526 529\n",
      "14 gluconate 0.71917486 529\n",
      "15 glutarateCDC 0.07947758 529\n",
      "16 glycine 0.1754455 529\n",
      "17 GMP 0.21481636 529\n",
      "18 hypotaurine 0.13786124 529\n",
      "19 inosinemonophosphateIMP 0.1049355 529\n",
      "20 citrulline 0.3101343 529\n",
      "21 methionine 0.8265809 529\n",
      "22 orotate 0.43921596 529\n",
      "23 glutathioneoxidizedGSSG 0.44185477 529\n",
      "24 phenylalanine 0.5449822 529\n",
      "25 phosphate 0.1123845 529\n",
      "26 proline 0.52237105 529\n",
      "27 lactate 0.07966341 529\n",
      "28 serine 0.23066866 529\n",
      "29 serotonin 0.14223865 529\n",
      "30 taurine 0.23443416 529\n",
      "31 deoxyuridine 0.23775719 529\n",
      "32 glutamine 0.06529527 529\n",
      "33 threonine 0.05658426 529\n",
      "34 tryptophan 0.31468958 529\n",
      "35 glucose 0.23422223 529\n",
      "36 betaine 0.046900786 529\n",
      "37 cysteine 0.11124033 529\n",
      "38 tyrosine 0.12921958 529\n",
      "39 pseudouridine 0.24352983 529\n",
      "40 UMP 0.5013357 529\n",
      "41 thymidine 0.6138009 529\n",
      "42 asparagine 0.24125509 529\n",
      "43 heptanoate 0.05364295 529\n",
      "44 hydroxyproline 0.2538134 529\n",
      "45 oxoproline 0.09298846 529\n",
      "46 pipecolate 0.3932863 529\n",
      "47 alphatocopherol 0.3962654 529\n",
      "48 Nacetylalanine 0.40329212 529\n",
      "49 citrate 0.78182364 529\n",
      "50 urate 0.10867361 529\n",
      "51 Nacetylglucosaminylasparagine 0.44251662 529\n",
      "52 creatine 0.23377451 529\n",
      "53 HHTrE 0.2633112 529\n",
      "54 methoxytyrosine 0.37864107 529\n",
      "55 palmitoyllinoleoylGPI 0.4387398 529\n",
      "56 palmitoyllinoleoylGPC 0.13528614 529\n",
      "57 stearoylsphingomyelind 0.13972338 529\n",
      "58 palmitoyloleoylGPC 0.21616095 529\n",
      "59 Nstearoylsphingosined 0.4871102 529\n",
      "60 ethylmalonate 0.09166056 529\n",
      "61 anserine 0.14862122 529\n",
      "62 glucuronate 0.16652635 529\n",
      "63 glycerophosphorylcholineGPC 0.46109015 529\n",
      "64 ribitol 0.1315335 529\n",
      "65 indolelactate 0.36347404 529\n",
      "66 glycylvaline 0.50202525 529\n",
      "67 arachidonoylglycerol 0.28211385 529\n",
      "68 stearoylarachidonoylGPI 0.43561774 529\n",
      "69 myristoylpalmitoylGPC 0.2852883 529\n",
      "70 maleate 0.25792468 529\n",
      "71 methylcytidine 0.43035156 529\n",
      "72 hexanoylcarnitineC 0.44038227 529\n",
      "73 tartronatehydroxymalonate 0.19116092 529\n",
      "74 homocitrulline 0.11796838 529\n",
      "75 ribonate 0.4097576 529\n",
      "76 threonate 0.53062165 529\n",
      "77 galactonate 0.49373958 529\n",
      "78 butyrylcarnitineC 0.15463352 529\n",
      "79 trigonellineNmethylnicotinate 0.17012738 529\n",
      "80 methylhistamine 0.23872451 529\n",
      "81 imidazoleacetate 0.4774328 529\n",
      "82 octanoylcarnitineC 0.07947253 529\n",
      "83 decanoylcarnitineC 0.14382184 529\n",
      "84 glycylleucine 0.522796 529\n",
      "85 campesterol 0.49705964 529\n",
      "86 Nacetylthreonine 0.41376376 529\n",
      "87 alphahydroxyisovalerate 0.17100173 529\n",
      "88 gammaglutamylthreonine 0.72342265 529\n",
      "89 erythronate 0.18483005 529\n",
      "90 aconitatecisortrans 0.36059648 529\n",
      "91 laurylcarnitineC 0.3538673 529\n",
      "92 dihydrouridine 0.23354223 529\n",
      "93 cysteineglutathionedisulfide 0.26519477 529\n",
      "94 methyluridineribothymidine 0.83779436 529\n",
      "95 methylguanine 0.30537248 529\n",
      "96 hydroxybutyrateGHB 0.30875203 529\n",
      "97 hydroxymethylvalerate 0.26585662 529\n",
      "98 eicosadienoylGPC 0.127932 529\n",
      "99 glycerophosphoglycerol 0.54849803 529\n",
      "100 glycerophosphoethanolamine 0.19279851 529\n",
      "101 mannitolsorbitol 0.3729995 529\n",
      "102 methylphosphate 0.69762 529\n",
      "103 Nacetylserine 0.38443148 529\n",
      "104 stearoylarachidonoylGPS 0.14538011 529\n",
      "105 ergothioneine 0.47062403 529\n",
      "106 RRdihydroxybutyrate 0.26467013 529\n",
      "107 dihydroxyisovalerate 0.17507727 529\n",
      "108 methylglutaconate 0.1811042 529\n",
      "109 galactosylhydroxylysine 0.68266296 529\n",
      "110 nicotinamideNoxide 0.49363428 529\n",
      "111 oxoarginine 0.52978414 529\n",
      "112 equolsulfate 0.29149193 529\n",
      "113 mannonate 0.6873604 529\n",
      "114 Rhydroxybutyrylcarnitine 0.033802018 529\n",
      "115 Nacetylcarnosine 0.62736154 529\n",
      "116 Ndeltaacetylornithine 0.49481386 529\n",
      "117 hydroxyphenylpropionatesulfate 0.27239877 529\n",
      "118 myristoleoylcarnitineC 0.51813996 529\n",
      "119 Nformylphenylalanine 0.62368065 529\n",
      "120 arabonatexylonate 0.29690486 529\n",
      "121 nonanoylcarnitineC 0.3916084 529\n",
      "122 palmitoylarachidonoylGPCn 0.6131253 529\n",
      "123 palmitoyldocosahexaenoylGPC 0.2305774 529\n",
      "124 enylstearoyloleoylGPCP 0.60865223 529\n",
      "125 tricosanoylsphingomyelind 0.43668872 529\n",
      "126 palmitoylpalmitoleoylGPC 0.44804102 529\n",
      "127 palmitoylarachidonoylGPE 0.4176073 529\n",
      "128 palmitoylarachidonoylGPI 0.04534255 529\n",
      "129 enylstearoylarachidonoylGPEP 0.4845128 529\n",
      "130 enylpalmitoyloleoylGPCP 0.37257808 529\n",
      "131 enylpalmitoylarachidonoylGPCP 0.16361445 529\n",
      "132 Npalmitoylsphinganined 0.49812993 529\n",
      "133 pentadecanoyllinoleoylGPC 0.09973766 529\n",
      "134 margaroyloleoylGPC 0.2353571 529\n",
      "135 palmitoyloleoylGPI 0.44307536 529\n",
      "136 palmitoleoyllinoleoylGPC 0.32218075 529\n",
      "137 margaroylarachidonoylGPC 0.27434584 529\n",
      "138 linoleoylarachidonoylGPCn 0.42378384 529\n",
      "139 myristoylarachidonoylGPC 0.55042344 529\n",
      "140 enylpalmitoylpalmitoleoylGPCP 0.6526481 529\n",
      "141 enylpalmitoylpalmitoylGPCP 0.7166679 529\n",
      "142 stearoyldihomolinolenoylGPInor 0.26299238 529\n",
      "143 oleoylarachidonoylGPE 0.12092089 529\n",
      "144 oleoyldocosahexaenoylGPE 0.5983181 529\n",
      "145 thioproline 0.13837801 529\n",
      "146 isocitriclactone 0.11900815 529\n",
      "147 Shydroxybutyrylcarnitine 0.56397384 529\n",
      "148 linoleoyllinolenoylGPC 0.34929627 529\n",
      "149 palmitoleoyllinolenoylGPC 0.24473189 529\n",
      "150 gammaglutamylalphalysine 0.41307175 529\n",
      "151 linoleoylarachidonoylglycerol 0.24346936 529\n",
      "152 oleoylarachidonoylglycerol 0.27166373 529\n",
      "153 oleoylarachidonoylGPI 0.38385373 529\n",
      "154 Npalmitoylsphingadienined 0.3463542 529\n",
      "155 Nbehenoylsphingadienined 0.20844394 529\n",
      "156 lignoceroylcarnitineC 0.39587095 529\n",
      "157 NNacetylspermidine 0.87515396 529\n",
      "158 tetradecadienoate 0.2566777 529\n",
      "159 NNdimethylalanine 0.4768265 529\n",
      "160 stearoylmeadoylGPIn 0.33973867 529\n",
      "161 dihydroxybenzoicacid 0.4330328 529\n",
      "162 pentoseacid 0.22635289 529\n",
      "163 methylimidazolelactate 0.024274051 529\n",
      "164 putrescine 0.3558252 529\n",
      "165 spermidine 0.9333424 529\n",
      "166 alphaketoglutarate 0.45106298 529\n",
      "167 hydroxyisobutyrate 0.3691698 529\n",
      "168 hydroxymethylglutarate 0.36459506 529\n",
      "169 phosphoglycerate 0.6722146 529\n",
      "170 hypoxanthine 0.77705526 529\n",
      "171 linoleaten 0.38586324 529\n",
      "172 laurate 0.57874525 529\n",
      "173 NNNtrimethyllysine 0.32668108 529\n",
      "174 methylthioadenosineMTA 0.79348326 529\n",
      "175 ribosephosphate 0.22275163 529\n",
      "176 arachidonaten 0.3194913 529\n",
      "177 arginine 0.4102328 529\n",
      "178 argininosuccinate 0.3816464 529\n",
      "179 aspartate 0.6459954 529\n",
      "180 biliverdin 0.086546086 529\n",
      "181 succinate 0.45502537 529\n",
      "182 hydroxybutyrateBHBA 0.0606917 529\n",
      "183 cholesterol 0.22089843 529\n",
      "184 sphingosine 0.24111566 529\n",
      "185 sphinganine 0.07719 529\n",
      "186 fumarate 0.2919652 529\n",
      "187 guanidinoacetate 0.87184167 529\n",
      "188 histamine 0.25438678 529\n",
      "189 histidine 0.17672238 529\n",
      "190 inosine 0.26965556 529\n",
      "191 myoinositol 0.0408965 529\n",
      "192 isoleucine 0.79375887 529\n",
      "193 aminoadipate 0.15892258 529\n",
      "194 leucine 0.42863348 529\n",
      "195 lysine 0.39138687 529\n",
      "196 malate 0.57015324 529\n",
      "197 palmitate 0.17071365 529\n",
      "198 nicotinamide 0.31636086 529\n",
      "199 stearate 1.2577932 529\n",
      "200 ornithine 0.107682735 529\n",
      "201 palmitoleaten 0.26400244 529\n",
      "202 salicylate 0.62754464 529\n",
      "203 spermine 0.8359778 529\n",
      "204 myristate 0.2662663 529\n",
      "205 urea 0.24384445 529\n",
      "206 uridine 0.64394337 529\n",
      "207 transurocanate 0.049603906 529\n",
      "208 glutamate 0.5292629 529\n",
      "209 valine 0.2533198 529\n",
      "210 pyridoxamine 0.30944064 529\n",
      "211 adenosine 0.22091392 529\n",
      "212 mannose 0.06438084 529\n",
      "213 dimethylglycine 0.20666428 529\n",
      "214 alanine 0.44243124 529\n",
      "215 malonate 0.48309523 529\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 47\u001b[0m\n\u001b[1;32m     37\u001b[0m     model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m     38\u001b[0m     layers\u001b[39m.\u001b[39mDense(\u001b[39m64\u001b[39m,activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,input_shape \u001b[39m=\u001b[39m input_shape),\n\u001b[1;32m     39\u001b[0m     layers\u001b[39m.\u001b[39mDropout(\u001b[39m0.3\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     layers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m     ])\n\u001b[1;32m     44\u001b[0m     model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     45\u001b[0m           loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     46\u001b[0m           metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbinary_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 47\u001b[0m     model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     48\u001b[0m     X_fwn\u001b[39m.\u001b[39;49miloc[train_index,features],y\u001b[39m.\u001b[39;49miloc[train_index,:],\n\u001b[1;32m     49\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m,\n\u001b[1;32m     50\u001b[0m     verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m     51\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_fwn\u001b[39m.\u001b[39;49miloc[test_index,features],y\u001b[39m.\u001b[39;49miloc[test_index,:]),\n\u001b[1;32m     52\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[earlystopping]\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     54\u001b[0m     met_loss \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(met_loss, model\u001b[39m.\u001b[39mget_metrics_result()[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m met_loss \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m best_loss:\n",
      "File \u001b[0;32m~/VSCodeProjects/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/VSCodeProjects/.venv/lib/python3.10/site-packages/keras/engine/training.py:1747\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1743\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1744\u001b[0m     }\n\u001b[1;32m   1745\u001b[0m     epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1747\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_epoch_end(epoch, epoch_logs)\n\u001b[1;32m   1748\u001b[0m training_logs \u001b[39m=\u001b[39m epoch_logs\n\u001b[1;32m   1749\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/VSCodeProjects/.venv/lib/python3.10/site-packages/keras/callbacks.py:453\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    451\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    452\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 453\u001b[0m     callback\u001b[39m.\u001b[39;49mon_epoch_end(epoch, logs)\n",
      "File \u001b[0;32m~/VSCodeProjects/.venv/lib/python3.10/site-packages/keras/callbacks.py:1221\u001b[0m, in \u001b[0;36mHistory.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39msetdefault(k, [])\u001b[39m.\u001b[39mappend(v)\n\u001b[1;32m   1219\u001b[0m \u001b[39m# Set the history attribute on the model after the epoch ends. This will\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# make sure that the state which is set is the latest one.\u001b[39;00m\n\u001b[0;32m-> 1221\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mhistory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/VSCodeProjects/.venv/lib/python3.10/site-packages/keras/engine/training.py:358\u001b[0m, in \u001b[0;36mModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    353\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIt looks like you are subclassing `Model` and you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mforgot to call `super().__init__()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m Always start with this line.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m         )\n\u001b[0;32m--> 358\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(name, value)\n",
      "File \u001b[0;32m~/VSCodeProjects/.venv/lib/python3.10/site-packages/keras/engine/base_layer.py:3163\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3160\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   3162\u001b[0m \u001b[39m# Wraps data structures in `Trackable`, unwraps `NoDependency` objects.\u001b[39;00m\n\u001b[0;32m-> 3163\u001b[0m value \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49msticky_attribute_assignment(\n\u001b[1;32m   3164\u001b[0m     trackable\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, value\u001b[39m=\u001b[39;49mvalue, name\u001b[39m=\u001b[39;49mname\n\u001b[1;32m   3165\u001b[0m )\n\u001b[1;32m   3167\u001b[0m reference_counts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_reference_counts\n\u001b[1;32m   3168\u001b[0m reference_counts[value] \u001b[39m=\u001b[39m reference_counts\u001b[39m.\u001b[39mget(value, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/VSCodeProjects/.venv/lib/python3.10/site-packages/tensorflow/python/trackable/data_structures.py:149\u001b[0m, in \u001b[0;36msticky_attribute_assignment\u001b[0;34m(trackable, name, value)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m   add_dependency \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m value \u001b[39m=\u001b[39m wrap_or_unwrap(value)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m add_dependency:\n\u001b[1;32m    151\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/VSCodeProjects/.venv/lib/python3.10/site-packages/tensorflow/python/trackable/data_structures.py:88\u001b[0m, in \u001b[0;36mwrap_or_unwrap\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     85\u001b[0m   \u001b[39m# pylint: enable=unidiomatic-typecheck\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__internal__.tracking.wrap\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_or_unwrap\u001b[39m(value):\n\u001b[1;32m     90\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Wraps input value into trackable data structures.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[39m  This is mostly useful for containers like list, dict, etc, which could contain\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m    Wrapped trackable data structure.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m   \u001b[39m# pylint: disable=unidiomatic-typecheck\u001b[39;00m\n\u001b[1;32m    106\u001b[0m   \u001b[39m# Exact type checking to avoid mucking up custom logic in list/dict\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   \u001b[39m# subclasses, e.g. collections.Counter.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlystopping = keras.callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "features = X_fwn.columns.isin(X_fwn.columns) # initialize feature selection with all as true\n",
    "#initial model to find best_loss score for initial target\n",
    "input_shape = [features.sum()]\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64,activation = 'relu',input_shape = input_shape),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics = ['binary_accuracy'])\n",
    "# test the model with 3 folds\n",
    "kf = KFold(n_splits=3,shuffle=True)\n",
    "for j, (train_index, test_index) in enumerate(kf.split(X_fwn)):\n",
    "    model.fit(\n",
    "    X_fwn.iloc[train_index,features],y.iloc[train_index,:],\n",
    "    epochs = 200,\n",
    "    verbose = 0,\n",
    "    validation_data=(X_fwn.iloc[test_index,features],y.iloc[test_index,:]),\n",
    "    callbacks=[earlystopping]\n",
    "    )\n",
    "    best_loss = min(best_loss, model.get_metrics_result()['loss'].numpy())\n",
    "print(best_loss)\n",
    "\n",
    "for i, met in enumerate(X_fwn.columns):\n",
    "    met_loss = 10000\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(X_fwn)):\n",
    "        input_shape = [features.sum()]\n",
    "        model = keras.Sequential([\n",
    "        layers.Dense(64,activation = 'relu',input_shape = input_shape),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1,activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['binary_accuracy'])\n",
    "        model.fit(\n",
    "        X_fwn.iloc[train_index,features],y.iloc[train_index,:],\n",
    "        epochs = 200,\n",
    "        verbose = 0,\n",
    "        validation_data=(X_fwn.iloc[test_index,features],y.iloc[test_index,:]),\n",
    "        callbacks=[earlystopping]\n",
    "        )\n",
    "        met_loss = min(met_loss, model.get_metrics_result()['loss'].numpy())\n",
    "    if met_loss <= best_loss:\n",
    "        features[i] = False\n",
    "    print(i,met,met_loss,features.sum())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "230619 - made it as far as 215 Malonate, still all 529 features are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
